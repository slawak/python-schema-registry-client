{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Python Rest Client Schema Registry Python Rest Client to interact against schema-registry confluent server to manage Avro Schemas resources. Requirements python 3.6+, avro-python3, fastavro, requests Installation pip install python-schema-registry-client When use this library? Usually, we have a situacion like this: So, our producers/consumers have to serialize/deserialize messages every time that they send/receive from Kafka topics. In this picture, we can imagine a Faust application receiving messages (encoded with an Avro schema) and we want to deserialize them, so we can ask the schema server to do that for us. In this scenario, the MessageSerializer is perfect. Also, could be a use case that we would like to have an Application only to administrate Avro Schemas (register, update compatibilities, delete old schemas, etc.), so the SchemaRegistryClient is perfect. Run Tests The tests are run against the Schema Server using docker compose , so you will need Docker and Docker Compose installed. ./scripts/test.sh","title":"Introduction"},{"location":"#python-rest-client-schema-registry","text":"Python Rest Client to interact against schema-registry confluent server to manage Avro Schemas resources.","title":"Python Rest Client Schema Registry"},{"location":"#requirements","text":"python 3.6+, avro-python3, fastavro, requests","title":"Requirements"},{"location":"#installation","text":"pip install python-schema-registry-client","title":"Installation"},{"location":"#when-use-this-library","text":"Usually, we have a situacion like this: So, our producers/consumers have to serialize/deserialize messages every time that they send/receive from Kafka topics. In this picture, we can imagine a Faust application receiving messages (encoded with an Avro schema) and we want to deserialize them, so we can ask the schema server to do that for us. In this scenario, the MessageSerializer is perfect. Also, could be a use case that we would like to have an Application only to administrate Avro Schemas (register, update compatibilities, delete old schemas, etc.), so the SchemaRegistryClient is perfect.","title":"When use this library?"},{"location":"#run-tests","text":"The tests are run against the Schema Server using docker compose , so you will need Docker and Docker Compose installed. ./scripts/test.sh","title":"Run Tests"},{"location":"client/","text":"Client The Schema Registry Client consumes the API exposed by the schema-registry to operate resources that are avro schemas. You probably won't use this but is good to know that exists. The MessageSerialzer is whom interact with the SchemaRegistryClient SchemaRegistryClient: SchemaRegistryClient A client that talks to a Schema Registry over HTTP def __init__ ( self , url , ca_location = None , cert_location = None , key_location = None , extra_headers = None ) Args : url ( str | dict ) url : Url to schema registry or dictionary containing client configuration . ca_location ( str ): File or directory path to CA certificate ( s ) for verifying the Schema Registry key . cert_location ( str ): Path to public key used for authentication . key_location ( str ): Path to private key used for authentication . extra_headers ( dict ): Extra headers to add on every requests . Methods: Get Schema get_schema ( subject , version = \"latest\" , headers = None ): If the subject is not found a Nametupled ( None , None , None ) is returned . Args : subject ( str ): subject name version ( int , optional ): version id . If is None , the latest schema is returned headers ( dict ): Extra headers to add on the requests Returns : SchemaVersion ( nametupled ): ( subject , schema_id , schema , version ) Get schema by id : get_by_id ( schema_id , headers = None ) Args : schema_id ( int ): Schema Id headers ( dict ): Extra headers to add on the requests Returns : avro . schema . RecordSchema : Avro Record schema Register a Schema: register ( subject , avro_schema , headers = None ) Args : subject ( str ): subject name avro_schema ( avro . schema . RecordSchema ): Avro schema to be registered headers ( dict ): Extra headers to add on the requests Returns : int : schema_id Delete Schema delete_subject ( subject , headers = None ) Args : subject ( str ): subject name headers ( dict ): Extra headers to add on the requests Returns : int : version of the schema deleted under this subject Check if a schema has already been registered under the specified subject: check_version ( subject , avro_schema , headers = None ) Args : subject ( str ): subject name avro_schema ( avro . schema . RecordSchema ): Avro schema headers ( dict ): Extra headers to add on the requests Returns : int : Schema version None : If schema not found . Test Compatibility: test_compatibility ( subject , avro_schema , version = \"latest\" , headers = None ) By default the latest version is checked against . Args : subject ( str ): subject name avro_schema ( avro . schema . RecordSchema ): Avro schema parsed headers ( dict ): Extra headers to add on the requests Returns : bool : True if compatible , False if not compatible Get Compatibility: get_compatibility ( subject , headers = None ) Get the current compatibility level for a subject . Result will be one of : Args : subject ( str ): subject name headers ( dict ): Extra headers to add on the requests Returns : str : one of 'NONE' , 'FULL' , 'FORWARD' , or 'BACKWARD' Raises : ClientError : if the request was unsuccessful or an invalid compatibility level was returned Update Compatibility: update_compatibility ( level , subject , headers = None ) Update the compatibility level for a subject . Args : level ( str ): ex : 'NONE' , 'FULL' , 'FORWARD' , or 'BACKWARD' headers ( dict ): Extra headers to add on the requests Returns : None","title":"Using the client"},{"location":"client/#client","text":"The Schema Registry Client consumes the API exposed by the schema-registry to operate resources that are avro schemas. You probably won't use this but is good to know that exists. The MessageSerialzer is whom interact with the SchemaRegistryClient","title":"Client"},{"location":"client/#schemaregistryclient","text":"SchemaRegistryClient A client that talks to a Schema Registry over HTTP def __init__ ( self , url , ca_location = None , cert_location = None , key_location = None , extra_headers = None ) Args : url ( str | dict ) url : Url to schema registry or dictionary containing client configuration . ca_location ( str ): File or directory path to CA certificate ( s ) for verifying the Schema Registry key . cert_location ( str ): Path to public key used for authentication . key_location ( str ): Path to private key used for authentication . extra_headers ( dict ): Extra headers to add on every requests .","title":"SchemaRegistryClient:"},{"location":"client/#methods","text":"","title":"Methods:"},{"location":"client/#get-schema","text":"get_schema ( subject , version = \"latest\" , headers = None ): If the subject is not found a Nametupled ( None , None , None ) is returned . Args : subject ( str ): subject name version ( int , optional ): version id . If is None , the latest schema is returned headers ( dict ): Extra headers to add on the requests Returns : SchemaVersion ( nametupled ): ( subject , schema_id , schema , version )","title":"Get Schema"},{"location":"client/#get-schema-by-id","text":"get_by_id ( schema_id , headers = None ) Args : schema_id ( int ): Schema Id headers ( dict ): Extra headers to add on the requests Returns : avro . schema . RecordSchema : Avro Record schema Register a Schema: register ( subject , avro_schema , headers = None ) Args : subject ( str ): subject name avro_schema ( avro . schema . RecordSchema ): Avro schema to be registered headers ( dict ): Extra headers to add on the requests Returns : int : schema_id","title":"Get schema by id:"},{"location":"client/#delete-schema","text":"delete_subject ( subject , headers = None ) Args : subject ( str ): subject name headers ( dict ): Extra headers to add on the requests Returns : int : version of the schema deleted under this subject Check if a schema has already been registered under the specified subject: check_version ( subject , avro_schema , headers = None ) Args : subject ( str ): subject name avro_schema ( avro . schema . RecordSchema ): Avro schema headers ( dict ): Extra headers to add on the requests Returns : int : Schema version None : If schema not found .","title":"Delete Schema"},{"location":"client/#test-compatibility","text":"test_compatibility ( subject , avro_schema , version = \"latest\" , headers = None ) By default the latest version is checked against . Args : subject ( str ): subject name avro_schema ( avro . schema . RecordSchema ): Avro schema parsed headers ( dict ): Extra headers to add on the requests Returns : bool : True if compatible , False if not compatible","title":"Test Compatibility:"},{"location":"client/#get-compatibility","text":"get_compatibility ( subject , headers = None ) Get the current compatibility level for a subject . Result will be one of : Args : subject ( str ): subject name headers ( dict ): Extra headers to add on the requests Returns : str : one of 'NONE' , 'FULL' , 'FORWARD' , or 'BACKWARD' Raises : ClientError : if the request was unsuccessful or an invalid compatibility level was returned","title":"Get Compatibility:"},{"location":"client/#update-compatibility","text":"update_compatibility ( level , subject , headers = None ) Update the compatibility level for a subject . Args : level ( str ): ex : 'NONE' , 'FULL' , 'FORWARD' , or 'BACKWARD' headers ( dict ): Extra headers to add on the requests Returns : None","title":"Update Compatibility:"},{"location":"faust/","text":"How to use it with Faust? This section describe how integrate this library with Faust Avro Schemas, Custom Codecs and Serializers Because we want to be sure that the message that we encode are valid, we use Avro Schemas . Also, Introduction to Schemas in Apache Kafka with the Confluent Schema Registry is a good post to start with schemas . Avro is used to define the data schema for a record's value. This schema describes the fields allowed in the value, along with their data types. In order to use avro schemas with Faust , we need to define a custom codec and a custom serializer able to talk with the schema-registry , and to do that, we will use the MessageSerializer . For our demostration, let's imagine that we have the folling schema : { \"type\" : \"record\" , \"namespace\" : \"com.example\" , \"name\" : \"AvroUsers\" , \"fields\" : [ { \"name\" : \"first_name\" , \"type\" : \"string\" }, { \"name\" : \"last_name\" , \"type\" : \"string\" } ] } Let's create the serializer codec: # codecs.avro.py from faust.serializers.codecs import Codec # get from the library from schema_registry.serializer import MessageSerializer class AvroSerializer ( MessageSerializer , Codec ): def __init__ ( self , schema_registry_client , destination_topic , schema , is_key = False ): self . schema_registry_client = schema_registry_client self . destination_topic = destination_topic self . schema = schema self . is_key = is_key MessageSerializer . __init__ ( self , schema_registry_client ) Codec . __init__ ( self ) def _loads ( self , s : bytes ): # method available on MessageSerializer return self . decode_message ( s ) def _dumps ( self , obj ): \"\"\" Given a parsed avro schema, encode a record for the given topic. The record is expected to be a dictionary. The schema is registered with the subject of 'topic-value' \"\"\" # method available on MessageSerializer return self . encode_record_with_schema ( topic = self . destination_topic , schema = self . schema , record = obj , is_key = self . is_key , ) Let's register the custom codec serializer # codecs.codec.py from avro.schema import SchemaFromJSONData from schema_registry.client import SchemaRegistryClient from codecs.avro import AvroSerializer # create an instance of the `SchemaRegistryClient` client = SchemaRegistryClient ( url = settings . SCHEMA_REGISTRY_URL ) # schema that we want to use. For this example we # are using a dict, but this schema could be located in a file called avro_user_schema.avsc avro_user_schema = SchemaFromJSONData ({ \"type\" : \"record\" , \"namespace\" : \"com.example\" , \"name\" : \"AvroUsers\" , \"fields\" : [ { \"name\" : \"first_name\" , \"type\" : \"string\" }, { \"name\" : \"last_name\" , \"type\" : \"string\" } ] }) avro_user_serializer = AvroSerializer ( schema_registry_client = client , destination_topic = \"users\" , schema = avro_user_schema ) # function used to register the codec def avro_user_codec (): return avro_user_serializer and ddd in setup.py the folloing code in order to tell faust where to find the custom codecs. # setup.py setup ( ... entry_points = { 'console_scripts' : [ 'example = example.app:main' , ], 'faust.codecs' : [ 'avro_users = example.codecs.avro:avro_user_codec' , ], }, ) Now the final step is to integrate the faust model with the AvroSerializer. # users.models class UserModel ( faust . Record , serializer = 'avro_users' ): first_name : str last_name : str Now our application is able to send and receive message using arvo schemas!!!! :-) import logging from your_project.app import app from .codecs.codec import avro_user_serializer from .models import UserModel users_topic = app . topic ( 'avro_users' , partitions = 1 , value_type = UserModel ) logger = logging . getLogger ( __name__ ) @app.agent ( users_topic ) async def users ( users ): async for user in users : logger . info ( \"Event received in topic avro_users\" ) logger . info ( f \"First Name: {user.first_name}, last name {user.last_name}\" ) @app.timer ( 5.0 , on_leader = True ) async def publish_users (): logger . info ( 'PUBLISHING ON LEADER FOR USERS APP!' ) user = { \"first_name\" : \"foo\" , \"last_name\" : \"bar\" } await users . send ( value = user , value_serializer = avro_user_serializer )","title":"Faust integration"},{"location":"faust/#how-to-use-it-with-faust","text":"This section describe how integrate this library with Faust","title":"How to use it with Faust?"},{"location":"faust/#avro-schemas-custom-codecs-and-serializers","text":"Because we want to be sure that the message that we encode are valid, we use Avro Schemas . Also, Introduction to Schemas in Apache Kafka with the Confluent Schema Registry is a good post to start with schemas . Avro is used to define the data schema for a record's value. This schema describes the fields allowed in the value, along with their data types. In order to use avro schemas with Faust , we need to define a custom codec and a custom serializer able to talk with the schema-registry , and to do that, we will use the MessageSerializer . For our demostration, let's imagine that we have the folling schema : { \"type\" : \"record\" , \"namespace\" : \"com.example\" , \"name\" : \"AvroUsers\" , \"fields\" : [ { \"name\" : \"first_name\" , \"type\" : \"string\" }, { \"name\" : \"last_name\" , \"type\" : \"string\" } ] } Let's create the serializer codec: # codecs.avro.py from faust.serializers.codecs import Codec # get from the library from schema_registry.serializer import MessageSerializer class AvroSerializer ( MessageSerializer , Codec ): def __init__ ( self , schema_registry_client , destination_topic , schema , is_key = False ): self . schema_registry_client = schema_registry_client self . destination_topic = destination_topic self . schema = schema self . is_key = is_key MessageSerializer . __init__ ( self , schema_registry_client ) Codec . __init__ ( self ) def _loads ( self , s : bytes ): # method available on MessageSerializer return self . decode_message ( s ) def _dumps ( self , obj ): \"\"\" Given a parsed avro schema, encode a record for the given topic. The record is expected to be a dictionary. The schema is registered with the subject of 'topic-value' \"\"\" # method available on MessageSerializer return self . encode_record_with_schema ( topic = self . destination_topic , schema = self . schema , record = obj , is_key = self . is_key , ) Let's register the custom codec serializer # codecs.codec.py from avro.schema import SchemaFromJSONData from schema_registry.client import SchemaRegistryClient from codecs.avro import AvroSerializer # create an instance of the `SchemaRegistryClient` client = SchemaRegistryClient ( url = settings . SCHEMA_REGISTRY_URL ) # schema that we want to use. For this example we # are using a dict, but this schema could be located in a file called avro_user_schema.avsc avro_user_schema = SchemaFromJSONData ({ \"type\" : \"record\" , \"namespace\" : \"com.example\" , \"name\" : \"AvroUsers\" , \"fields\" : [ { \"name\" : \"first_name\" , \"type\" : \"string\" }, { \"name\" : \"last_name\" , \"type\" : \"string\" } ] }) avro_user_serializer = AvroSerializer ( schema_registry_client = client , destination_topic = \"users\" , schema = avro_user_schema ) # function used to register the codec def avro_user_codec (): return avro_user_serializer and ddd in setup.py the folloing code in order to tell faust where to find the custom codecs. # setup.py setup ( ... entry_points = { 'console_scripts' : [ 'example = example.app:main' , ], 'faust.codecs' : [ 'avro_users = example.codecs.avro:avro_user_codec' , ], }, ) Now the final step is to integrate the faust model with the AvroSerializer. # users.models class UserModel ( faust . Record , serializer = 'avro_users' ): first_name : str last_name : str Now our application is able to send and receive message using arvo schemas!!!! :-) import logging from your_project.app import app from .codecs.codec import avro_user_serializer from .models import UserModel users_topic = app . topic ( 'avro_users' , partitions = 1 , value_type = UserModel ) logger = logging . getLogger ( __name__ ) @app.agent ( users_topic ) async def users ( users ): async for user in users : logger . info ( \"Event received in topic avro_users\" ) logger . info ( f \"First Name: {user.first_name}, last name {user.last_name}\" ) @app.timer ( 5.0 , on_leader = True ) async def publish_users (): logger . info ( 'PUBLISHING ON LEADER FOR USERS APP!' ) user = { \"first_name\" : \"foo\" , \"last_name\" : \"bar\" } await users . send ( value = user , value_serializer = avro_user_serializer )","title":"Avro Schemas, Custom Codecs and Serializers"},{"location":"schemaregistry_server/","text":"Schema Registry Server This section provides you just an introduction about the Schema Server . Schema Registry provides a serving layer for your metadata. It provides a RESTful interface for storing and retrieving Avro schemas. It stores a versioned history of all schemas, provides multiple compatibility settings and allows evolution of schemas according to the configured compatibility settings and expanded Avro support. It provides serializers that plug into Apache Kafka\u00ae clients that handle schema storage and retrieval for Kafka messages that are sent in the Avro format. Schema Registry is a distributed storage layer for Avro Schemas which uses Kafka as its underlying storage mechanism. Some key design decisions: Assigns globally unique ID to each registered schema. Allocated IDs are guaranteed to be monotonically increasing but not necessarily consecutive. Kafka provides the durable backend, and functions as a write-ahead changelog for the state of Schema Registry and the schemas it contains. Schema Registry is designed to be distributed, with single-primary architecture, and ZooKeeper/Kafka coordinates primary election (based on the configuration). API Schemas GET /schemas/ids/{int: id} - Get the schema string identified by the input ID Subjects GET /subjects - Get a list of registered subjects. [Missing] GET /subjects/(string: subject)/versions - Get a list of versions registered under the specified subject [Missing] DELETE /subjects/(string: subject) - Deletes the specified subject and its associated compatibility level if registered. It is recommended to use this API only when a topic needs to be recycled or in development environment. GET /subjects/(string: subject)/versions/(versionId: version) - Get a specific version of the schema registered under this subject Check response GET /subjects/(string: subject)/versions/(versionId: version)/schema - Get the avro schema for the specified version of this subject. The unescaped schema only is returned. [Missing] POST /subjects/(string: subject)/versions - Register a new schema under the specified subject and receive a schema id POST /subjects/(string: subject) - Check if a schema has already been registered under the specified subject. If so, this returns the schema string along with its globally unique identifier, its version under this subject and the subject name. DELETE /subjects/(string: subject)/versions/(versionId: version) - Deletes a specific version of the schema registered under this subject. This only deletes the version and the schema ID remains intact making it still possible to decode data using the schema ID. This API is recommended to be used only in development environments or under extreme circumstances where-in, its required to delete a previously registered schema for compatibility purposes or re-register previously registered schema. [Missing] Compatibility POST /compatibility/subjects/(string: subject)/versions/(versionId: version) - Test input schema against a particular version of a subject's schema for compatibility. Note that the compatibility level applied for the check is the configured compatibility level for the subject (http:get:: /config/(string: subject)). If this subject's compatibility level was never changed, then the global compatibility level applies (http:get:: /config). Config GET /config - Get global compatibility level. PUT /config - Update global compatibility level. [Missing] GET /config/(string: subject) - Get compatibility level for a subject. [Missing] PUT /config/(string: subject) - Update compatibility level for the specified subject. Too know more about the API go here","title":"Schema Registry"},{"location":"schemaregistry_server/#schema-registry-server","text":"This section provides you just an introduction about the Schema Server . Schema Registry provides a serving layer for your metadata. It provides a RESTful interface for storing and retrieving Avro schemas. It stores a versioned history of all schemas, provides multiple compatibility settings and allows evolution of schemas according to the configured compatibility settings and expanded Avro support. It provides serializers that plug into Apache Kafka\u00ae clients that handle schema storage and retrieval for Kafka messages that are sent in the Avro format. Schema Registry is a distributed storage layer for Avro Schemas which uses Kafka as its underlying storage mechanism. Some key design decisions: Assigns globally unique ID to each registered schema. Allocated IDs are guaranteed to be monotonically increasing but not necessarily consecutive. Kafka provides the durable backend, and functions as a write-ahead changelog for the state of Schema Registry and the schemas it contains. Schema Registry is designed to be distributed, with single-primary architecture, and ZooKeeper/Kafka coordinates primary election (based on the configuration).","title":"Schema Registry Server"},{"location":"schemaregistry_server/#api","text":"","title":"API"},{"location":"schemaregistry_server/#schemas","text":"GET /schemas/ids/{int: id} - Get the schema string identified by the input ID","title":"Schemas"},{"location":"schemaregistry_server/#subjects","text":"GET /subjects - Get a list of registered subjects. [Missing] GET /subjects/(string: subject)/versions - Get a list of versions registered under the specified subject [Missing] DELETE /subjects/(string: subject) - Deletes the specified subject and its associated compatibility level if registered. It is recommended to use this API only when a topic needs to be recycled or in development environment. GET /subjects/(string: subject)/versions/(versionId: version) - Get a specific version of the schema registered under this subject Check response GET /subjects/(string: subject)/versions/(versionId: version)/schema - Get the avro schema for the specified version of this subject. The unescaped schema only is returned. [Missing] POST /subjects/(string: subject)/versions - Register a new schema under the specified subject and receive a schema id POST /subjects/(string: subject) - Check if a schema has already been registered under the specified subject. If so, this returns the schema string along with its globally unique identifier, its version under this subject and the subject name. DELETE /subjects/(string: subject)/versions/(versionId: version) - Deletes a specific version of the schema registered under this subject. This only deletes the version and the schema ID remains intact making it still possible to decode data using the schema ID. This API is recommended to be used only in development environments or under extreme circumstances where-in, its required to delete a previously registered schema for compatibility purposes or re-register previously registered schema. [Missing]","title":"Subjects"},{"location":"schemaregistry_server/#compatibility","text":"POST /compatibility/subjects/(string: subject)/versions/(versionId: version) - Test input schema against a particular version of a subject's schema for compatibility. Note that the compatibility level applied for the check is the configured compatibility level for the subject (http:get:: /config/(string: subject)). If this subject's compatibility level was never changed, then the global compatibility level applies (http:get:: /config).","title":"Compatibility"},{"location":"schemaregistry_server/#config","text":"GET /config - Get global compatibility level. PUT /config - Update global compatibility level. [Missing] GET /config/(string: subject) - Get compatibility level for a subject. [Missing] PUT /config/(string: subject) - Update compatibility level for the specified subject. Too know more about the API go here","title":"Config"},{"location":"serializer/","text":"Message Serializer Class that serialize and deserialize messages. It interacts with the SchemaRegistryClient to get Avro Schemas in order to process messages. In your application you will intereact with it. Usage: from schema_registry.client import SchemaRegistryClient from schema_registry.serializer import MessageSerializer client = SchemaRegistryClient ( \"http://127.0.0.1:8080\" ) message_serielizer = MessageSerializer ( client ) # Let's imagine that we have the foillowing schema. avro_user_schema = SchemaFromJSONData ({ \"type\" : \"record\" , \"namespace\" : \"com.example\" , \"name\" : \"AvroUsers\" , \"fields\" : [ { \"name\" : \"first_name\" , \"type\" : \"string\" }, { \"name\" : \"last_name\" , \"type\" : \"string\" }, { \"name\" : \"age\" , \"type\" : \"int\" }, ], }) # We want to encode the user_record with avro_user_schema user_record = { \"first_name\" : \"my_first_name\" , \"last_name\" : \"my_last_name\" , \"age\" : 20 , } message_encoded = message_serializer . encode_record_with_schema ( \"user\" , avro_user_schema , user_record ) # this is because the message encoded reserved 5 bytes for the schema_id assert len ( message_encoded ) > 5 assert isinstance ( message_encoded , bytes ) # now decode the message message_decoded = message_serializer . decode_message ( message_encoded ) assert message_decoded == user_record # Now if we send a bad record bad_record = { \"first_name\" : \"my_first_name\" , \"last_name\" : \"my_last_name\" , \"age\" : \"my_age\" } message_serializer . encode_record_with_schema ( \"user\" , user_schema , bad_record ) # Exception!! TypeError : unsupported operand type ( s ) for << : 'str' and 'int' Class and Methods: MessageSerializer Args : schemaregistry_client ( schema_registry . client . SchemaRegistryClient ): Http Client Encode record with a Schema : encode_record_with_schema ( topic , schema , record , is_key = False ) Args : topic ( str ): Topic name schema ( avro . schema . RecordSchema ): Avro Schema record ( dict ): An object to serialize is_key ( bool ): If the record is a key Returns : bytes : Encoded record with schema ID as bytes Encode a record with a schema id : encode_record_with_schema_id ( schema_id , record , is_key = False ): Args : schema_id ( int ): integer ID record ( dict ): An object to serialize is_key ( bool ): If the record is a key Returns : func : decoder function Decode a message encoded previously: decode_message ( message , is_key = False ) Args : message ( str | bytes or None ): message key or value to be decoded Returns : dict : Decoded message contents .","title":"Message Serializer"},{"location":"serializer/#message-serializer","text":"Class that serialize and deserialize messages. It interacts with the SchemaRegistryClient to get Avro Schemas in order to process messages. In your application you will intereact with it.","title":"Message Serializer"},{"location":"serializer/#usage","text":"from schema_registry.client import SchemaRegistryClient from schema_registry.serializer import MessageSerializer client = SchemaRegistryClient ( \"http://127.0.0.1:8080\" ) message_serielizer = MessageSerializer ( client ) # Let's imagine that we have the foillowing schema. avro_user_schema = SchemaFromJSONData ({ \"type\" : \"record\" , \"namespace\" : \"com.example\" , \"name\" : \"AvroUsers\" , \"fields\" : [ { \"name\" : \"first_name\" , \"type\" : \"string\" }, { \"name\" : \"last_name\" , \"type\" : \"string\" }, { \"name\" : \"age\" , \"type\" : \"int\" }, ], }) # We want to encode the user_record with avro_user_schema user_record = { \"first_name\" : \"my_first_name\" , \"last_name\" : \"my_last_name\" , \"age\" : 20 , } message_encoded = message_serializer . encode_record_with_schema ( \"user\" , avro_user_schema , user_record ) # this is because the message encoded reserved 5 bytes for the schema_id assert len ( message_encoded ) > 5 assert isinstance ( message_encoded , bytes ) # now decode the message message_decoded = message_serializer . decode_message ( message_encoded ) assert message_decoded == user_record # Now if we send a bad record bad_record = { \"first_name\" : \"my_first_name\" , \"last_name\" : \"my_last_name\" , \"age\" : \"my_age\" } message_serializer . encode_record_with_schema ( \"user\" , user_schema , bad_record ) # Exception!! TypeError : unsupported operand type ( s ) for << : 'str' and 'int'","title":"Usage:"},{"location":"serializer/#class-and-methods","text":"MessageSerializer Args : schemaregistry_client ( schema_registry . client . SchemaRegistryClient ): Http Client","title":"Class and Methods:"},{"location":"serializer/#encode-record-with-a-schema","text":"encode_record_with_schema ( topic , schema , record , is_key = False ) Args : topic ( str ): Topic name schema ( avro . schema . RecordSchema ): Avro Schema record ( dict ): An object to serialize is_key ( bool ): If the record is a key Returns : bytes : Encoded record with schema ID as bytes","title":"Encode record with a Schema:"},{"location":"serializer/#encode-a-record-with-a-schema-id","text":"encode_record_with_schema_id ( schema_id , record , is_key = False ): Args : schema_id ( int ): integer ID record ( dict ): An object to serialize is_key ( bool ): If the record is a key Returns : func : decoder function","title":"Encode a record with a schema id:"},{"location":"serializer/#decode-a-message-encoded-previously","text":"decode_message ( message , is_key = False ) Args : message ( str | bytes or None ): message key or value to be decoded Returns : dict : Decoded message contents .","title":"Decode a message encoded previously:"}]}